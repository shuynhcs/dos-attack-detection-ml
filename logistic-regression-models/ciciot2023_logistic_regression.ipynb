{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string as str\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as sk_metrics\n",
    "import tempfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"data/ciciot2023_dataset.csv\"\n",
    "df = pd.read_csv(file_path, header=0, index_col=0, nrows=100000).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].mask(df['label'] == 'BenignTraffic', int(0), inplace=True)\n",
    "df['label'].mask(df['label'] == 'DDoS-TCP_Flood', int(1), inplace=True)\n",
    "df['label'].mask(df['label'] == 'DDoS-UDP_Flood', int(1), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    df[col] = pd.to_numeric(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = df.sample(frac=0.8, random_state=1)\n",
    "test_dataset = df.drop(train_dataset.index)\n",
    "print(\"Train: {0}, Test: {1}\".format(len(train_dataset), len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train_dataset.iloc[:, 0:-1], train_dataset.iloc[:, -1]\n",
    "x_test, y_test = test_dataset.iloc[:, 0:-1], test_dataset.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = tf.convert_to_tensor(x_train, dtype=tf.float32), tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "x_test, y_test = tf.convert_to_tensor(x_test, dtype=tf.float32), tf.convert_to_tensor(y_test, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(tf.Module):\n",
    "  def __init__(self, x):\n",
    "    # Initialize the mean and standard deviation for normalization\n",
    "    self.mean = tf.Variable(tf.math.reduce_mean(x, axis=0))\n",
    "    self.std = tf.Variable(tf.math.reduce_std(x, axis=0))\n",
    "\n",
    "  def norm(self, x):\n",
    "    # Normalize the input\n",
    "    return (x - self.mean)/self.std\n",
    "\n",
    "  def unnorm(self, x):\n",
    "    # Unnormalize the input\n",
    "    return (x * self.std) + self.mean\n",
    "\n",
    "norm_x = Normalize(x_train)\n",
    "x_train_norm, x_test_norm = norm_x.norm(x_train), norm_x.norm(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss(y_pred, y):\n",
    "  # Compute the log loss function\n",
    "  ce = tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=y_pred)\n",
    "  return tf.reduce_mean(ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(tf.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    self.built = False\n",
    "\n",
    "  def __call__(self, x, train=True):\n",
    "    # Initialize the model parameters on the first call\n",
    "    if not self.built:\n",
    "      # Randomly generate the weights and the bias term\n",
    "      rand_w = tf.random.uniform(shape=[x.shape[-1], 1], seed=22)\n",
    "      rand_b = tf.random.uniform(shape=[], seed=22)\n",
    "      self.w = tf.Variable(rand_w)\n",
    "      self.b = tf.Variable(rand_b)\n",
    "      self.built = True\n",
    "    # Compute the model output\n",
    "    z = tf.add(tf.matmul(x, self.w), self.b)\n",
    "    z = tf.squeeze(z, axis=1)\n",
    "    if train:\n",
    "      return z\n",
    "    return tf.sigmoid(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(y_pred, thresh=0.5):\n",
    "  # Return a tensor with  `1` if `y_pred` > `0.5`, and `0` otherwise\n",
    "  return tf.cast(y_pred > thresh, tf.float32)\n",
    "\n",
    "def accuracy(y_pred, y):\n",
    "  # Return the proportion of matches between `y_pred` and `y`\n",
    "  y_pred = tf.math.sigmoid(y_pred)\n",
    "  y_pred_class = predict_class(y_pred)\n",
    "  check_equal = tf.cast(y_pred_class == y,tf.float32)\n",
    "  acc_val = tf.reduce_mean(check_equal)\n",
    "  return acc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_norm, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=x_train.shape[0]).batch(batch_size)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test_norm, y_test))\n",
    "test_dataset = test_dataset.shuffle(buffer_size=x_test.shape[0]).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training parameters\n",
    "epochs = 2000\n",
    "learning_rate = 0.01\n",
    "train_losses, test_losses = [], []\n",
    "train_accs, test_accs = [], []\n",
    "\n",
    "# Set up the training loop and begin training\n",
    "for epoch in range(epochs):\n",
    "  batch_losses_train, batch_accs_train = [], []\n",
    "  batch_losses_test, batch_accs_test = [], []\n",
    "\n",
    "  # Iterate over the training data\n",
    "  for x_batch, y_batch in train_dataset:\n",
    "    with tf.GradientTape() as tape:\n",
    "      y_pred_batch = log_reg(x_batch)\n",
    "      batch_loss = log_loss(y_pred_batch, y_batch)\n",
    "    batch_acc = accuracy(y_pred_batch, y_batch)\n",
    "    # Update the parameters with respect to the gradient calculations\n",
    "    grads = tape.gradient(batch_loss, log_reg.variables)\n",
    "    for g,v in zip(grads, log_reg.variables):\n",
    "      v.assign_sub(learning_rate * g)\n",
    "    # Keep track of batch-level training performance\n",
    "    batch_losses_train.append(batch_loss)\n",
    "    batch_accs_train.append(batch_acc)\n",
    "\n",
    "  # Iterate over the testing data\n",
    "  for x_batch, y_batch in test_dataset:\n",
    "    y_pred_batch = log_reg(x_batch)\n",
    "    batch_loss = log_loss(y_pred_batch, y_batch)\n",
    "    batch_acc = accuracy(y_pred_batch, y_batch)\n",
    "    # Keep track of batch-level testing performance\n",
    "    batch_losses_test.append(batch_loss)\n",
    "    batch_accs_test.append(batch_acc)\n",
    "\n",
    "  # Keep track of epoch-level model performance\n",
    "  train_loss, train_acc = tf.reduce_mean(batch_losses_train), tf.reduce_mean(batch_accs_train)\n",
    "  test_loss, test_acc = tf.reduce_mean(batch_losses_test), tf.reduce_mean(batch_accs_test)\n",
    "  train_losses.append(train_loss)\n",
    "  train_accs.append(train_acc)\n",
    "  test_losses.append(test_loss)\n",
    "  test_accs.append(test_acc)\n",
    "  if epoch % 20 == 0:\n",
    "    print(f\"Epoch: {epoch}, Training log loss: {train_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(epochs), train_losses, label = \"Training loss\")\n",
    "plt.plot(range(epochs), test_losses, label = \"Testing loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Log loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Log loss vs training iterations\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(epochs), train_accs, label = \"Training accuracy\")\n",
    "plt.plot(range(epochs), test_accs, label = \"Testing accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy vs training iterations\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Final training log loss: {train_losses[-1]:.3f}\")\n",
    "print(f\"Final testing log Loss: {test_losses[-1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Final training accuracy: {train_accs[-1]:.3f}\")\n",
    "print(f\"Final testing accuracy: {test_accs[-1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(y, y_classes, typ):\n",
    "  # Compute the confusion matrix and normalize it\n",
    "  plt.figure(figsize=(10,10))\n",
    "  confusion = sk_metrics.confusion_matrix(y.numpy(), y_classes.numpy())\n",
    "  confusion_normalized = confusion / confusion.sum(axis=1, keepdims=True)\n",
    "  axis_labels = range(2)\n",
    "  ax = sns.heatmap(\n",
    "      confusion_normalized, xticklabels=axis_labels, yticklabels=axis_labels,\n",
    "      cmap='Blues', annot=True, fmt='.4f', square=True)\n",
    "  plt.title(f\"Confusion matrix: {typ}\")\n",
    "  plt.ylabel(\"True label\")\n",
    "  plt.xlabel(\"Predicted label\")\n",
    "\n",
    "y_pred_train, y_pred_test = log_reg(x_train_norm, train=False), log_reg(x_test_norm, train=False)\n",
    "train_classes, test_classes = predict_class(y_pred_train), predict_class(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_confusion_matrix(y_train, train_classes, 'Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_confusion_matrix(y_test, test_classes, 'Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExportModule(tf.Module):\n",
    "  def __init__(self, model, norm_x, class_pred):\n",
    "    # Initialize pre- and post-processing functions\n",
    "    self.model = model\n",
    "    self.norm_x = norm_x\n",
    "    self.class_pred = class_pred\n",
    "\n",
    "  @tf.function(input_signature=[tf.TensorSpec(shape=[None, None], dtype=tf.float32)])\n",
    "  def __call__(self, x):\n",
    "    # Run the `ExportModule` for new data points\n",
    "    x = self.norm_x.norm(x)\n",
    "    y = self.model(x, train=False)\n",
    "    y = self.class_pred(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_export = ExportModule(model=log_reg,\n",
    "                              norm_x=norm_x,\n",
    "                              class_pred=predict_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tempfile.mkdtemp()\n",
    "save_path = os.path.join(models, 'log_reg_export')\n",
    "tf.saved_model.save(log_reg_export, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_loaded = tf.saved_model.load(save_path)\n",
    "test_preds = log_reg_loaded(x_test)\n",
    "test_preds[:10].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, test_preds, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
